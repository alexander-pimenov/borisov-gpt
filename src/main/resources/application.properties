spring.application.name=Moy_LLM_Eto_ne_tvoy_LLM
server.port=8181

#Настройки для Spring AI, чтобы работать не с cURL, а через API, который предоставляет Spring AI
#указываем куда делать запросы к модели
spring.ai.ollama.base-url=http://localhost:11431
#указываем модель внутри Ollama
spring.ai.ollama.chat.model=gemma3:4b-it-q4_K_M
#Так же тут для spring ai можно указать настройки для top-k, top-p, temperature, то что передается в запросе в json к модели,
#но мы это будет передавать в момент отсылки запроса, а не в application.properties

#Подключение к БД
spring.datasource.url=jdbc:postgresql://localhost:5432/ragdb
spring.datasource.username=postgres
spring.datasource.password=postgres

# Включим этот флаг, чтобы разрешить self-injection (инжекшен самого в себя), как в сервисе ChatService для
# корректной работы @Transactional, т.к. по дефолту он выключен.
spring.main.allow-circular-references=true


#spring.ai.vectorstore.pgvector.table-name=